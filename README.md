# Детекция людей на изображениях и видео с YOLOv8

Данный проект представляет собой систему детекции людей на изображениях и видео с использованием модели YOLOv8, обученной на датасете WiderPerson.

## Запуск проекта

### Требования
- Python 3.11 или выше
- Зависимости из requirements.txt

### Установка

```bash
# Клонирование репозитория
git clone https://github.com/MukhtarovTimerlan/Human_detection.git
cd Human_detection

# Установка зависимостей
pip install -r requirements.txt
```

### Запуск приложения

```bash
streamlit run app.py
```
После запуска приложение будет доступно по адресу http://localhost:8501 в вашем веб-браузере.


### Запуск обучения
```bash
python install_wider_person.py
python dataset_convertion.py
```
В интерактивном режиме `train.ipynb`


## Структура проекта

- `run.py` - файл проверки зависимостей, наличия модели и запуска приложения  
- `app.py` - основной файл приложения Streamlit  
- `requirements.txt` - файл с зависимостями  
- `train.ipynb` - ноутбук с кодом обучения модели  
- `dataset_convertion.ipynb` - ноутбук с кодом конвертации датасета  
- `widerperson_yolo.yaml` - конфигурационный файл для обучения YOLO
- `runs/detect/custom_yolov8n2/weights/` - директория с весами обученной модели
- `datasets/` - директория с датасетами   
- `model_widerperson_raw.ipynb` - проверка метрик модели без дообучения  
- `fast_check_yolo.ipynb` - проверка работоспособности модели на случайном видео  
- `yolov8n.pt` - базовые веса модели из коробки  
- `widerperson_yolo.yaml` - конфиг для обучения модели

## Технические детали

### Качество кода
- Код организован с соблюдением принципов PEP8
- Весь код размещен в GitHub-репозитории
- Структура проекта логически разбита на модули и компоненты
- Зависимости зафиксированы в файле requirements.txt

### Выбор технологий и инструментов

#### Основные фреймворки и библиотеки:
- **Ultralytics YOLO** - современная реализация модели YOLO для задач детекции объектов. Выбрана благодаря простоте использования, высокой производительности.   
- **Streamlit** - фреймворк для быстрого создания веб-приложений на Python. Использован для создания простого и интуитивно понятного пользовательского интерфейса.
- **OpenCV** - библиотека компьютерного зрения для обработки изображений и видео.
- **PyTorch** - основной фреймворк машинного обучения, на котором базируется YOLO.

#### Методы и модели:
- **YOLOv8n** - "nano" вариант модели YOLOv8, оптимальный баланс между точностью и скоростью работы. Что очень кстати к задаче детекции в реальном времени  
- **Transfer Learning** - использование предобученной модели YOLOv8n с дальнейшей тонкой настройкой на нашем датасете.
- **Замораживание слоев** - для ускорения обучения и предотвращения переобучения.

### Обработка данных

#### Подготовка датасета:
- В качестве основы использовался датасет WiderPerson, содержащий разнообразные изображения людей в различных условиях.
- Датасет был конвертирован из оригинального формата в формат YOLO с помощью скрипта `dataset_convertion.ipynb`.
- Разделение на обучающую (8000 изображений) и валидационную (1000 изображений) выборки. (Как в изначальном наборе данных)

#### Аугментация данных:
- В качестве аугментации данных использовались стандартные аугментации через параметр конфига augment: true:  
- **Горизонтальное отражение (Horizontal Flip)**  
- **Масштабирование/Сдвиг (Scale/Translate)**    
- **HSV-аугментации**  
- - Изменение насыщенности (Hue, Saturation)  
- - Изменение яркости (Value)  
- - Пространственные искажения (Affine Transformations)  
  
Аугментация данных помогла повысить робастность модели к различным условиям съемки и положениям людей.
  
### Обучение модели

#### Состав набора данных:
- Тренировочный набор: 8000 изображений
- Валидационный набор: 1000 изображений

#### Метрики оценки:
- **mAP50** - средняя точность при пороге IoU 0.5
- **mAP50-95** - средняя точность при порогах IoU от 0.5 до 0.95 с шагом 0.05
- **Precision** - точность детекции (TP / (TP + FP))
- **Recall** - полнота детекции (TP / (TP + FN))
 

Изначально модель обучалась на COCO датасете, поэтому я проверил ее показатели без дообучения на Wider Person  
и получил следующие показатели на валидационной выборке:  

mAP@0.5 = 0.242. Качество детекции низкое.  
Precision =	0.717. Модель делает мало ложных срабатываний.  
Recall = 0.505. Модель пропускает почти половину людей.    
mAP50-95 = 0.242. Плохая работа при разных порогах IoU.    
  
Причины низкого качества    
WiderPerson содержит сложные сцены: толпы, частично скрытых людей, специфические ракурсы.  
В COCO таких сцен меньше следовательно модель не адаптирована.    
  
В WiderPerson классы riders (2) и partially-visible persons (3) могли быть неправильно отображены на person (0).  
  
в WiderPerson изображения разных разрешений и есть меньше 640x640, модель YOLO теряет детализацию.  
  
Попробуем дообучить модель YOLO на новых данных, чтобы улучшить ее обобщающую способность.    
Для этого заморозим первые 10 слоев модели.

#### Параметры обучения:
- Количество эпох: 100 (в силу ограниченности ресурсов обучил 15 на протяжении больше 6 часов)  
- Размер батча: 8
- Размер изображения: 640x640
- Оптимизатор: SGD с начальной скоростью обучения 0.01

### Тестирование и валидация

Тестирование модели проводилось на валидационном наборе данных. Критерии успешности:
- mAP50 > 0.65
- mAP50-95 > 0.4

По результатам обучения достигнуты следующие показатели:  
P          R          mAP50     mAP50-95  
0.796      0.599      0.717      0.449  

Это намного лучше, чем было, однако довольно низко для системы повышенной безопасности. При дальнейшем обучении возможно  
было получить более высокие метрики.  
Дополнительно было проведено различное тестирование на различных видеофрагментах для оценки работы в реальных условиях.  
  
### Интеграция и деплой  
  
Решение представлено в виде веб-приложения на базе Streamlit, что обеспечивает простое взаимодействие с пользователем:
1. Пользователь может загрузить изображение или видеофайл  
2. Модель обрабатывает загруженные данные и выполняет детекцию людей  
3. Результаты отображаются на экране с визуализацией ограничивающих рамок и подсчетом количества обнаруженных людей  
  
### Масштабируемость и оптимизация

- Для повышения производительности при обработке видео реализована обработка только каждого 4-го кадра  
- Модель экспортирована в формат ONNX для возможности использования на различных платформах  
- Установлен порог конфиденциальности 0.5 для фильтрации ложных срабатываний  
  
### Интерфейс и удобство использования  
  
Приложение имеет простой и интуитивный интерфейс:  
- Выбор типа входных данных (изображение/видео)  
- Загрузка файла через стандартный элемент интерфейса  
- Отображение результата с визуализацией обнаруженных людей  
- Счетчик количества людей на изображении/видео  
- Ограничение в 200 Мб для видео.
